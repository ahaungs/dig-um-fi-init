% to start editing, read the content template.tex in here and start
% editing.
\section{KET: Elementary Particle Physics}

\sectauthor{Alexander Schmidt, RWTH Aachen}

\subsection{Existing Federated Infrastructures}
Over the last decades the field of experimental high-energy particle
physics has experienced a dramatic inflation of both the amount of
data and the reuquired resources to process them. In particular, the
experiments at the CERN Large Hadron Collider (LHC) have played a
pioneering role. The Worldwide LHC Computing Grid (WLCG) project has
been founded to handle and process the data produced by the LHC
experiments. Still today  the WLCG is the world's larges computing
grid. It consists of around 170 computing centers in more than 40
countries.  It is supported by many associated national and
international grids across the world, such as European Grid
Infrastructure (EGI) and Open Science Grid (OSG), based in the US, as well as many other
regional grids.  The WLCG consists of four layers, or "tiers"; 0, 1, 2
and 3. Each tier provides a specific set of services. The Tier 0 is at
CERN and is responsible for the safe-keeping of the raw data (first
copy). Thirteen Tier 2 centers are responsible for a proportional
share of raw and reconstructed data, large-scale reprocessing and
safe-keeping of corresponding output, distribution of data to Tier
2s. The Tier 2s are typically universities and other scientific
institutes, which can store sufficient data and provide adequate
computing power for specific analysis tasks. They handle analysis
requirements and proportional share of simulated event production and
reconstruction.

Add descriptions of other federated infrastructures in HEP???

Add descriptions of KHUK ???


\subsection{Technologies Employed}
Currently the WLCG defines four component layers,  networking, hardware, middleware and
physics analysis software. The most important middleware stacks used
in the WLCG are from the European Middleware Initiative, which
combines several middleware providers (ARC, gLite, UNICORE and
dCache); the Globus Toolkit developed by the Globus Alliance; and the
Virtual Data Toolkit. 



\subsection{Current Issues, future challenges}
In the realm of LHC computing, the data volume and complexity will
increase dramatically with the upcoming high-luminosity phase of the
collider. Compared to 2016, an increase of computing resources by a
factor of 60 will be needed. However, the assuming a flat budget, the
increase through improving technologies is expected to be. Also the
experiments at FAIR and and new large scale projects in astro-particle
physics will have similar requirements. 


\subsection{Infrastructures to be Federated}

Aus subjektiver Sicht: Was sollte föderiert werden?  Warum hilft die
Föderierung der entsprechenden Infrastrukturen, was geht dann, das
jetzt nicht geht?
